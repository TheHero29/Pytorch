{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TheHero29/Pytorch/blob/main/_downloads/0e6615c5a7bc71e01ff3c51217ea00da/tensorqs_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HRyklU6ZF_yg"
      },
      "outputs": [],
      "source": [
        "# For tips on running notebooks in Google Colab, see\n",
        "# https://pytorch.org/tutorials/beginner/colab\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZzaLTN4vF_yh"
      },
      "source": [
        "[Learn the Basics](intro.html) \\|\\|\n",
        "[Quickstart](quickstart_tutorial.html) \\|\\| **Tensors** \\|\\| [Datasets &\n",
        "DataLoaders](data_tutorial.html) \\|\\|\n",
        "[Transforms](transforms_tutorial.html) \\|\\| [Build\n",
        "Model](buildmodel_tutorial.html) \\|\\|\n",
        "[Autograd](autogradqs_tutorial.html) \\|\\|\n",
        "[Optimization](optimization_tutorial.html) \\|\\| [Save & Load\n",
        "Model](saveloadrun_tutorial.html)\n",
        "\n",
        "Tensors\n",
        "=======\n",
        "\n",
        "Tensors are a specialized data structure that are very similar to arrays\n",
        "and matrices. In PyTorch, we use tensors to encode the inputs and\n",
        "outputs of a model, as well as the model's parameters.\n",
        "\n",
        "Tensors are similar to [NumPy's](https://numpy.org/) ndarrays, except\n",
        "that tensors can run on GPUs or other hardware accelerators. In fact,\n",
        "tensors and NumPy arrays can often share the same underlying memory,\n",
        "eliminating the need to copy data (see\n",
        "`bridge-to-np-label`{.interpreted-text role=\"ref\"}). Tensors are also\n",
        "optimized for automatic differentiation (we\\'ll see more about that\n",
        "later in the [Autograd](autogradqs_tutorial.html) section). If you're\n",
        "familiar with ndarrays, you'll be right at home with the Tensor API. If\n",
        "not, follow along!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "L7hgb58EF_yj"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i8vungAbF_yl"
      },
      "source": [
        "Initializing a Tensor\n",
        "=====================\n",
        "\n",
        "Tensors can be initialized in various ways. Take a look at the following\n",
        "examples:\n",
        "\n",
        "**Directly from data**\n",
        "\n",
        "Tensors can be created directly from data. The data type is\n",
        "automatically inferred.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "zXmHAyMZF_yl"
      },
      "outputs": [],
      "source": [
        "data = [[1, 2],[3, 4]]\n",
        "x_data = torch.tensor(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4YmUtglF_ym"
      },
      "source": [
        "**From a NumPy array**\n",
        "\n",
        "Tensors can be created from NumPy arrays (and vice versa - see\n",
        "`bridge-to-np-label`{.interpreted-text role=\"ref\"}).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "VV-rjkv_F_ym"
      },
      "outputs": [],
      "source": [
        "np_array = np.array(data)\n",
        "x_np = torch.from_numpy(np_array)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Exz0LjLYF_yn"
      },
      "source": [
        "**From another tensor:**\n",
        "\n",
        "The new tensor retains the properties (shape, datatype) of the argument\n",
        "tensor, unless explicitly overridden.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FwnPiOAcF_yo",
        "outputId": "aab0f385-45da-4f26-8e59-534069c04503"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_data: \n",
            " tensor([[1, 2],\n",
            "        [3, 4]]) \n",
            "\n",
            "Ones Tensor: \n",
            " tensor([[1, 1],\n",
            "        [1, 1]]) \n",
            "\n",
            "Random Tensor: \n",
            " tensor([[0.2583, 0.9417],\n",
            "        [0.0621, 0.5128]]) \n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(f\"x_data: \\n\",x_data,'\\n')\n",
        "x_ones = torch.ones_like(x_data) # retains the properties of x_data\n",
        "print(f\"Ones Tensor: \\n {x_ones} \\n\")\n",
        "\n",
        "x_rand = torch.rand_like(x_data, dtype=torch.float) # overrides the datatype of x_data\n",
        "print(f\"Random Tensor: \\n {x_rand} \\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSENfz5RF_yo"
      },
      "source": [
        "**With random or constant values:**\n",
        "\n",
        "`shape` is a tuple of tensor dimensions. In the functions below, it\n",
        "determines the dimensionality of the output tensor.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UrC1GjT3F_yp",
        "outputId": "56110fd5-25a8-4d78-b0f9-5e49a2d0d471"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Tensor: <class 'tuple'>\n",
            " tensor([[0.4798, 0.1453, 0.0968],\n",
            "        [0.6237, 0.1447, 0.7497]]) \n",
            "\n",
            "Ones Tensor: <class 'torch.Tensor'>\n",
            " tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.]]) \n",
            "\n",
            "Zeros Tensor: <class 'torch.Tensor'>\n",
            " tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]])\n"
          ]
        }
      ],
      "source": [
        "shape = (2,3)\n",
        "rand_tensor = torch.rand(shape)\n",
        "ones_tensor = torch.ones(shape)\n",
        "zeros_tensor = torch.zeros(shape)\n",
        "\n",
        "print(f\"Random Tensor: {type(shape)}\\n {rand_tensor} \\n\")\n",
        "print(f\"Ones Tensor: {type(ones_tensor)}\\n {ones_tensor} \\n\")\n",
        "print(f\"Zeros Tensor: {type(zeros_tensor)}\\n {zeros_tensor}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2bQcnmdF_yp"
      },
      "source": [
        "------------------------------------------------------------------------\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQJLwvikF_yp"
      },
      "source": [
        "Attributes of a Tensor\n",
        "======================\n",
        "\n",
        "Tensor attributes describe their shape, datatype, and the device on\n",
        "which they are stored.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nt5OqIScF_yp",
        "outputId": "c8fcd774-f9a4-462d-d209-17ee2c920174"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of tensor: torch.Size([3, 4])\n",
            "Datatype of tensor: torch.float32\n",
            "Device tensor is stored on: cpu\n"
          ]
        }
      ],
      "source": [
        "tensor = torch.rand(3,4)\n",
        "\n",
        "print(f\"Shape of tensor: {tensor.shape}\")\n",
        "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
        "print(f\"Device tensor is stored on: {tensor.device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1Sd39hzF_yp"
      },
      "source": [
        "------------------------------------------------------------------------\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XtTMSkcxF_yq"
      },
      "source": [
        "Operations on Tensors\n",
        "=====================\n",
        "\n",
        "Over 1200 tensor operations, including arithmetic, linear algebra,\n",
        "matrix manipulation (transposing, indexing, slicing), sampling and more\n",
        "are comprehensively described\n",
        "[here](https://pytorch.org/docs/stable/torch.html).\n",
        "\n",
        "Each of these operations can be run on the CPU and\n",
        "[Accelerator](https://pytorch.org/docs/stable/torch.html#accelerators)\n",
        "such as CUDA, MPS, MTIA, or XPU. If you're using Colab, allocate an\n",
        "accelerator by going to Runtime \\> Change runtime type \\> GPU.\n",
        "\n",
        "By default, tensors are created on the CPU. We need to explicitly move\n",
        "tensors to the accelerator using `.to` method (after checking for\n",
        "accelerator availability). Keep in mind that copying large tensors\n",
        "across devices can be expensive in terms of time and memory!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_TShJjXF_yq",
        "outputId": "c0e6d77f-1c45-4fbe-9450-13e82b1f3a57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device tensor is stored on: cuda:0\n",
            "Current accelerator: cuda\n"
          ]
        }
      ],
      "source": [
        "# We move our tensor to the current accelerator if available\n",
        "if torch.accelerator.is_available():\n",
        "    tensor = tensor.to(torch.accelerator.current_accelerator())\n",
        "    print(f\"Device tensor is stored on: {tensor.device}\")\n",
        "    print(f\"Current accelerator: {torch.accelerator.current_accelerator()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUFljzm-F_yq"
      },
      "source": [
        "Try out some of the operations from the list. If you\\'re familiar with\n",
        "the NumPy API, you\\'ll find the Tensor API a breeze to use.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swZwj1X4F_yq"
      },
      "source": [
        "**Standard numpy-like indexing and slicing:**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n8jqQAyDF_yq",
        "outputId": "7ee13d3e-03d5-459c-d59d-9a64e6c5c90c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First row: tensor([[[1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1.]],\n",
            "\n",
            "        [[1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1.]],\n",
            "\n",
            "        [[1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1.]],\n",
            "\n",
            "        [[1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1.]]])\n",
            "First column: tensor([[[1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1.]],\n",
            "\n",
            "        [[1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1.]],\n",
            "\n",
            "        [[1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1.]],\n",
            "\n",
            "        [[1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1.]]])\n",
            "Last column: tensor([[[1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1.]],\n",
            "\n",
            "        [[1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1.]],\n",
            "\n",
            "        [[1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1.]],\n",
            "\n",
            "        [[1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1.]]])\n",
            "tensor([[[[0., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.]],\n",
            "\n",
            "         [[0., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.]],\n",
            "\n",
            "         [[0., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.]],\n",
            "\n",
            "         [[0., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.]]],\n",
            "\n",
            "\n",
            "        [[[1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.]],\n",
            "\n",
            "         [[1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.]],\n",
            "\n",
            "         [[1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.]],\n",
            "\n",
            "         [[1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.]]],\n",
            "\n",
            "\n",
            "        [[[1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.]],\n",
            "\n",
            "         [[1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.]],\n",
            "\n",
            "         [[1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.]],\n",
            "\n",
            "         [[1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.]]],\n",
            "\n",
            "\n",
            "        [[[1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.]],\n",
            "\n",
            "         [[1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.]],\n",
            "\n",
            "         [[1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.]],\n",
            "\n",
            "         [[1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.]]]])\n"
          ]
        }
      ],
      "source": [
        "# its just like multi dimentional array i.e an arrray inside an array inside an array streching till n.\n",
        "# dimentions specified by list with size n, and value of elements in list beign size along that axes\n",
        "# good rule of thumb is for a slice like [0,1,:,0] -> check 1st hyper tensor amoung all tensors printed, then 2nd one amoung that particular tensor, then the whole as specified,\n",
        "\n",
        "## ie just think like accessing elements of ndarray, no need to imagine fully. idk how or where it'll be used I'll see. and learn accordingly\n",
        "tensor = torch.ones(4, 4, 4,4)\n",
        "print(f\"First row: {tensor[0]}\")\n",
        "print(f\"First column: {tensor[:, 0]}\")\n",
        "tensor[0,:,0,0] = 0\n",
        "print(f\"Last column: {tensor[..., -1]}\")\n",
        "print(tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8z04e_qTF_yq"
      },
      "source": [
        "**Joining tensors** You can use `torch.cat` to concatenate a sequence of\n",
        "tensors along a given dimension. See also\n",
        "[torch.stack](https://pytorch.org/docs/stable/generated/torch.stack.html),\n",
        "another tensor joining operator that is subtly different from\n",
        "`torch.cat`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8KG0RToF_yr",
        "outputId": "d2cd3e99-8005-484d-b3b9-195655e7d8eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[[0., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.]],\n",
            "\n",
            "         [[0., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.]],\n",
            "\n",
            "         [[0., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.]],\n",
            "\n",
            "         [[0., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.]],\n",
            "\n",
            "         [[0., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.]],\n",
            "\n",
            "         [[0., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.]],\n",
            "\n",
            "         [[0., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.]],\n",
            "\n",
            "         [[0., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.]],\n",
            "\n",
            "         [[0., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.]],\n",
            "\n",
            "         [[0., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.]],\n",
            "\n",
            "         [[0., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.]],\n",
            "\n",
            "         [[0., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.]]],\n",
            "\n",
            "\n",
            "        [[[1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.]],\n",
            "\n",
            "         [[1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.]],\n",
            "\n",
            "         [[1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.]],\n",
            "\n",
            "         [[1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.]],\n",
            "\n",
            "         [[1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.]],\n",
            "\n",
            "         [[1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.]],\n",
            "\n",
            "         [[1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.]],\n",
            "\n",
            "         [[1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.]],\n",
            "\n",
            "         [[1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.]],\n",
            "\n",
            "         [[1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.]],\n",
            "\n",
            "         [[1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.]],\n",
            "\n",
            "         [[1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.]]],\n",
            "\n",
            "\n",
            "        [[[1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.]],\n",
            "\n",
            "         [[1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.]],\n",
            "\n",
            "         [[1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.]],\n",
            "\n",
            "         [[1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.]],\n",
            "\n",
            "         [[1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.]],\n",
            "\n",
            "         [[1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.]],\n",
            "\n",
            "         [[1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.]],\n",
            "\n",
            "         [[1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.]],\n",
            "\n",
            "         [[1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.]],\n",
            "\n",
            "         [[1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.]],\n",
            "\n",
            "         [[1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.]],\n",
            "\n",
            "         [[1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.]]],\n",
            "\n",
            "\n",
            "        [[[1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.]],\n",
            "\n",
            "         [[1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.]],\n",
            "\n",
            "         [[1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.]],\n",
            "\n",
            "         [[1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.]],\n",
            "\n",
            "         [[1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.]],\n",
            "\n",
            "         [[1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.]],\n",
            "\n",
            "         [[1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.]],\n",
            "\n",
            "         [[1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.]],\n",
            "\n",
            "         [[1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.]],\n",
            "\n",
            "         [[1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.]],\n",
            "\n",
            "         [[1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.]],\n",
            "\n",
            "         [[1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.]]]])\n"
          ]
        }
      ],
      "source": [
        "t1 = torch.cat([tensor, tensor, tensor], dim=1)\n",
        "print(t1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QbfzWiIWF_yr"
      },
      "source": [
        "**Arithmetic operations**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AL9dlDjXF_yr",
        "outputId": "33372bc7-10a3-4905-f0d8-8152ab28bb02"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[0., 1., 1., 1.],\n",
              "          [1., 1., 1., 1.],\n",
              "          [1., 1., 1., 1.],\n",
              "          [1., 1., 1., 1.]],\n",
              "\n",
              "         [[0., 1., 1., 1.],\n",
              "          [1., 1., 1., 1.],\n",
              "          [1., 1., 1., 1.],\n",
              "          [1., 1., 1., 1.]],\n",
              "\n",
              "         [[0., 1., 1., 1.],\n",
              "          [1., 1., 1., 1.],\n",
              "          [1., 1., 1., 1.],\n",
              "          [1., 1., 1., 1.]],\n",
              "\n",
              "         [[0., 1., 1., 1.],\n",
              "          [1., 1., 1., 1.],\n",
              "          [1., 1., 1., 1.],\n",
              "          [1., 1., 1., 1.]]],\n",
              "\n",
              "\n",
              "        [[[1., 1., 1., 1.],\n",
              "          [1., 1., 1., 1.],\n",
              "          [1., 1., 1., 1.],\n",
              "          [1., 1., 1., 1.]],\n",
              "\n",
              "         [[1., 1., 1., 1.],\n",
              "          [1., 1., 1., 1.],\n",
              "          [1., 1., 1., 1.],\n",
              "          [1., 1., 1., 1.]],\n",
              "\n",
              "         [[1., 1., 1., 1.],\n",
              "          [1., 1., 1., 1.],\n",
              "          [1., 1., 1., 1.],\n",
              "          [1., 1., 1., 1.]],\n",
              "\n",
              "         [[1., 1., 1., 1.],\n",
              "          [1., 1., 1., 1.],\n",
              "          [1., 1., 1., 1.],\n",
              "          [1., 1., 1., 1.]]],\n",
              "\n",
              "\n",
              "        [[[1., 1., 1., 1.],\n",
              "          [1., 1., 1., 1.],\n",
              "          [1., 1., 1., 1.],\n",
              "          [1., 1., 1., 1.]],\n",
              "\n",
              "         [[1., 1., 1., 1.],\n",
              "          [1., 1., 1., 1.],\n",
              "          [1., 1., 1., 1.],\n",
              "          [1., 1., 1., 1.]],\n",
              "\n",
              "         [[1., 1., 1., 1.],\n",
              "          [1., 1., 1., 1.],\n",
              "          [1., 1., 1., 1.],\n",
              "          [1., 1., 1., 1.]],\n",
              "\n",
              "         [[1., 1., 1., 1.],\n",
              "          [1., 1., 1., 1.],\n",
              "          [1., 1., 1., 1.],\n",
              "          [1., 1., 1., 1.]]],\n",
              "\n",
              "\n",
              "        [[[1., 1., 1., 1.],\n",
              "          [1., 1., 1., 1.],\n",
              "          [1., 1., 1., 1.],\n",
              "          [1., 1., 1., 1.]],\n",
              "\n",
              "         [[1., 1., 1., 1.],\n",
              "          [1., 1., 1., 1.],\n",
              "          [1., 1., 1., 1.],\n",
              "          [1., 1., 1., 1.]],\n",
              "\n",
              "         [[1., 1., 1., 1.],\n",
              "          [1., 1., 1., 1.],\n",
              "          [1., 1., 1., 1.],\n",
              "          [1., 1., 1., 1.]],\n",
              "\n",
              "         [[1., 1., 1., 1.],\n",
              "          [1., 1., 1., 1.],\n",
              "          [1., 1., 1., 1.],\n",
              "          [1., 1., 1., 1.]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "# This computes the matrix multiplication between two tensors. y1, y2, y3 will have the same value\n",
        "# ``tensor.T`` returns the transpose of a tensor\n",
        "y1 = tensor @ tensor.mT\n",
        "y2 = tensor.matmul(tensor.mT)\n",
        "\n",
        "y3 = torch.rand_like(y1)\n",
        "torch.matmul(tensor, tensor.T, out=y3)\n",
        "\n",
        "\n",
        "# This computes the element-wise product. z1, z2, z3 will have the same value\n",
        "z1 = tensor * tensor\n",
        "z2 = tensor.mul(tensor)\n",
        "\n",
        "z3 = torch.rand_like(tensor)\n",
        "torch.mul(tensor, tensor, out=z3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5a14sldF_yr"
      },
      "source": [
        "**Single-element tensors** If you have a one-element tensor, for example\n",
        "by aggregating all values of a tensor into one value, you can convert it\n",
        "to a Python numerical value using `item()`:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4rih5PjF_yr",
        "outputId": "a234a2e4-6767-4969-dddb-7a11d5b357ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'> 252.0 <class 'float'>\n"
          ]
        }
      ],
      "source": [
        "agg = tensor.sum()\n",
        "agg_item = agg.item()\n",
        "print(type(agg),agg_item, type(agg_item))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arNpq-J0F_yr"
      },
      "source": [
        "**In-place operations** Operations that store the result into the\n",
        "operand are called in-place. They are denoted by a `_` suffix. For\n",
        "example: `x.copy_(y)`, `x.t_()`, will change `x`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rgl2uFLKF_yr",
        "outputId": "c0023271-da6b-4ad1-eac2-e94db3d10cc7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[[0., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.]],\n",
            "\n",
            "         [[0., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.]],\n",
            "\n",
            "         [[0., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.]],\n",
            "\n",
            "         [[0., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.]]],\n",
            "\n",
            "\n",
            "        [[[1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.]],\n",
            "\n",
            "         [[1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.]],\n",
            "\n",
            "         [[1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.]],\n",
            "\n",
            "         [[1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.]]],\n",
            "\n",
            "\n",
            "        [[[1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.]],\n",
            "\n",
            "         [[1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.]],\n",
            "\n",
            "         [[1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.]],\n",
            "\n",
            "         [[1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.]]],\n",
            "\n",
            "\n",
            "        [[[1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.]],\n",
            "\n",
            "         [[1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.]],\n",
            "\n",
            "         [[1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.]],\n",
            "\n",
            "         [[1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1.]]]]) \n",
            "\n",
            "tensor([[[[5., 6., 6., 6.],\n",
            "          [6., 6., 6., 6.],\n",
            "          [6., 6., 6., 6.],\n",
            "          [6., 6., 6., 6.]],\n",
            "\n",
            "         [[5., 6., 6., 6.],\n",
            "          [6., 6., 6., 6.],\n",
            "          [6., 6., 6., 6.],\n",
            "          [6., 6., 6., 6.]],\n",
            "\n",
            "         [[5., 6., 6., 6.],\n",
            "          [6., 6., 6., 6.],\n",
            "          [6., 6., 6., 6.],\n",
            "          [6., 6., 6., 6.]],\n",
            "\n",
            "         [[5., 6., 6., 6.],\n",
            "          [6., 6., 6., 6.],\n",
            "          [6., 6., 6., 6.],\n",
            "          [6., 6., 6., 6.]]],\n",
            "\n",
            "\n",
            "        [[[6., 6., 6., 6.],\n",
            "          [6., 6., 6., 6.],\n",
            "          [6., 6., 6., 6.],\n",
            "          [6., 6., 6., 6.]],\n",
            "\n",
            "         [[6., 6., 6., 6.],\n",
            "          [6., 6., 6., 6.],\n",
            "          [6., 6., 6., 6.],\n",
            "          [6., 6., 6., 6.]],\n",
            "\n",
            "         [[6., 6., 6., 6.],\n",
            "          [6., 6., 6., 6.],\n",
            "          [6., 6., 6., 6.],\n",
            "          [6., 6., 6., 6.]],\n",
            "\n",
            "         [[6., 6., 6., 6.],\n",
            "          [6., 6., 6., 6.],\n",
            "          [6., 6., 6., 6.],\n",
            "          [6., 6., 6., 6.]]],\n",
            "\n",
            "\n",
            "        [[[6., 6., 6., 6.],\n",
            "          [6., 6., 6., 6.],\n",
            "          [6., 6., 6., 6.],\n",
            "          [6., 6., 6., 6.]],\n",
            "\n",
            "         [[6., 6., 6., 6.],\n",
            "          [6., 6., 6., 6.],\n",
            "          [6., 6., 6., 6.],\n",
            "          [6., 6., 6., 6.]],\n",
            "\n",
            "         [[6., 6., 6., 6.],\n",
            "          [6., 6., 6., 6.],\n",
            "          [6., 6., 6., 6.],\n",
            "          [6., 6., 6., 6.]],\n",
            "\n",
            "         [[6., 6., 6., 6.],\n",
            "          [6., 6., 6., 6.],\n",
            "          [6., 6., 6., 6.],\n",
            "          [6., 6., 6., 6.]]],\n",
            "\n",
            "\n",
            "        [[[6., 6., 6., 6.],\n",
            "          [6., 6., 6., 6.],\n",
            "          [6., 6., 6., 6.],\n",
            "          [6., 6., 6., 6.]],\n",
            "\n",
            "         [[6., 6., 6., 6.],\n",
            "          [6., 6., 6., 6.],\n",
            "          [6., 6., 6., 6.],\n",
            "          [6., 6., 6., 6.]],\n",
            "\n",
            "         [[6., 6., 6., 6.],\n",
            "          [6., 6., 6., 6.],\n",
            "          [6., 6., 6., 6.],\n",
            "          [6., 6., 6., 6.]],\n",
            "\n",
            "         [[6., 6., 6., 6.],\n",
            "          [6., 6., 6., 6.],\n",
            "          [6., 6., 6., 6.],\n",
            "          [6., 6., 6., 6.]]]])\n"
          ]
        }
      ],
      "source": [
        "print(f\"{tensor} \\n\")\n",
        "tensor.add_(5)\n",
        "print(tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oxws4kJWF_ys"
      },
      "source": [
        "<div style=\"background-color: #54c7ec; color: #fff; font-weight: 700; padding-left: 10px; padding-top: 5px; padding-bottom: 5px\"><strong>NOTE:</strong></div>\n",
        "\n",
        "<div style=\"background-color: #f3f4f7; padding-left: 10px; padding-top: 10px; padding-bottom: 10px; padding-right: 10px\">\n",
        "\n",
        "<p>In-place operations save some memory, but can be problematic when computing derivatives because of an immediate lossof history. Hence, their use is discouraged.</p>\n",
        "\n",
        "</div>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jW0BITZBF_ys"
      },
      "source": [
        "------------------------------------------------------------------------\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgPWjQ82F_ys"
      },
      "source": [
        "Bridge with NumPy {#bridge-to-np-label}\n",
        "=================\n",
        "\n",
        "Tensors on the CPU and NumPy arrays can share their underlying memory\n",
        "locations, and changing one will change the other.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6TIx5n6F_ys"
      },
      "source": [
        "Tensor to NumPy array\n",
        "=====================\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SE_lxO6UF_ys"
      },
      "outputs": [],
      "source": [
        "t = torch.ones(5)\n",
        "print(f\"t: {t}\")\n",
        "n = t.numpy()\n",
        "print(f\"n: {n}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5jEoSIkF_ys"
      },
      "source": [
        "A change in the tensor reflects in the NumPy array.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lh7lBHQRF_yt"
      },
      "outputs": [],
      "source": [
        "t.add_(1)\n",
        "print(f\"t: {t}\")\n",
        "print(f\"n: {n}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5RmP1v8F_yt"
      },
      "source": [
        "NumPy array to Tensor\n",
        "=====================\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "hPpf4OoBF_yt"
      },
      "outputs": [],
      "source": [
        "n = np.ones(5)\n",
        "t = torch.from_numpy(n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cld6YXo1F_yt"
      },
      "source": [
        "Changes in the NumPy array reflects in the tensor.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F5HAIOJbF_yt",
        "outputId": "432a37ba-da8a-4c57-9e94-df80e67899a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t: tensor([4., 4., 4., 4., 4.], dtype=torch.float64)\n",
            "n: [4. 4. 4. 4. 4.]\n"
          ]
        }
      ],
      "source": [
        "np.add(n, 1, out=n)\n",
        "np.add(n,2)\n",
        "print(f\"t: {t}\")\n",
        "print(f\"n: {n}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}